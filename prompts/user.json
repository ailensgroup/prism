{
    "doc": "\n    **Objective:**\n    - Rank the five corporate disclosure document types by their likelihood of containing the best answer to the question, from MOST relevant (best first) to least relevant.\n\n    **Task:**\n    1) Understand the Question\n    - Determine whether the question seeks: strategy/risks/full-year context, recent quarterly performance/updates, a specific material event/announcement, governance/compensation/board matters, or earnings commentary/guidance/Q&A.\n\n    2) Map Intent to Document Types (use standard definitions)\n    - 10-K (Index 1): Annual, comprehensive overview. Best for strategy, full-year data, risk factors, major segments/markets, long-term trends.\n    - 10-Q (Index 2): Quarterly updates to financial condition and operations. Best for the latest quarter's figures and material changes since 10-K.\n    - 8-K (Index 3): Unscheduled material events (M&A, leadership changes, guidance updates, litigation, restructurings, press releases).\n    - DEF14A (Index 0): Governance, board composition, executive compensation, shareholder proposals, voting matters.\n    - Earnings (Index 4): Press release/call transcript with quarterly results, KPIs, and forward-looking commentary/guidance.\n\n    3) Relevance Heuristics and Ties\n    - Prioritize the document most likely to directly contain the answer.\n    - If the question is about: \n        • Strategy/risks/full-year → 10-K (#1) outranks others.\n        • Latest quarterly figures/material changes → 10-Q (#2), then Earnings (#4).\n        • Specific/dated event → 8-K (#3), then Earnings (#4) if it was discussed on the call.\n        • Governance/compensation/board → DEF14A (#0) first.\n        • Guidance/outlook/targets → Earnings (#4) first, then 10-Q (#2).\n    - Break ties by: (1) document with more direct commentary/metrics for the topic, (2) recency implied by the question, (3) formal disclosure precedence (8-K for events; DEF14A for governance).\n\n    4) Output Format (STRICT)\n    - Return ONLY a Python list of the FIVE indices, ordered from most relevant to least relevant.\n    - No explanations, no extra text, no JSON, no quotes.\n    - Example: [1, 2, 4, 0, 3]\n    \n    {icl_section}\n\n    **Question:**\n    {user_question}\n\n    **Document Types (with fixed indices):**\n    [Document Index 0] DEF14A\n    [Document Index 1] 10-K\n    [Document Index 2] 10-Q\n    [Document Index 3] 8-K\n    [Document Index 4] Earnings\n    ",
    "chunk": "\n    **Objective:**\n    - Identify the {actual_k} most relevant text chunks for answering the financial question and return ONLY their original indices, ordered from most relevant (best first) to least within the top {actual_k}.\n\n    **Task:**\n    1) Understand the Question\n    - Determine the primary financial intent (e.g., liquidity/cash, leverage/debt, profitability/margins, guidance/outlook, risk factors, segment performance, revenue drivers).\n    - Extract key entities (company, segment, product) and time references (e.g., 'as of Q2 FY2025', 'year-over-year', 'latest quarter').\n\n    2) Evaluate Each Text Chunk\n    - Use the ORIGINAL index shown in the chunk header.\n    - Assess relevance using this rubric (in order of priority):\n        A. Directness: Does the chunk directly answer the question or provide the exact metric/data/definition asked?\n        B. Specificity: Presence of quantitative figures, time stamps, definitions, or explicit management statements over generic commentary.\n        C. Temporal Alignment: Aligns with the period implied in the question (e.g., 'latest quarter', 'as of' dates).\n        D. Company/Entity Match: Addresses the same company/segment/product named or implied by the question.\n        E. Completeness: Contains enough context to stand on its own (not a dangling reference).\n        F. Consistency: No internal contradictions relative to the question framing.\n\n    3) Select and Rank Top {actual_k}\n    - Choose the {actual_k} highest-scoring chunks.\n    - Rank by the rubric above; put the BEST (most directly and completely responsive) first.\n    - If multiple chunks repeat the same content, keep the strongest one and down-rank near-duplicates.\n\n    4) Output Format (STRICT)\n    - Return ONLY a flat Python list with EXACTLY {actual_k} integers corresponding to ORIGINAL chunk indices.\n    - No explanations, no extra text, no JSON, no quotes.\n\n    {icl_section}\n\n    **Question:**\n    {user_question}\n\n    **Text Chunks:**\n    "
}